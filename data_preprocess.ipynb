{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5d33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a243b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"data\")\n",
    "\n",
    "TRENDS_DATA = DATA_ROOT / \"google_trends\"\n",
    "STOCKS_DATA = DATA_ROOT / \"market\"\n",
    "PROCESSED_DATA = DATA_ROOT / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12204327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read_csv(file_path)->Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df.empty:\n",
    "            # logging.warning(f\"DataFrame from {file_path} is empty.\")\n",
    "            return None\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        # logging.warning(f\"Error reading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e0cd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 103/103 stock data files.\n",
      "Loaded 2409/3003 trends data files.\n"
     ]
    }
   ],
   "source": [
    "stocks_dfs: List[pd.DataFrame] = []\n",
    "trends_dfs: List[pd.Series] = []\n",
    "\n",
    "for f in STOCKS_DATA.glob(\"*.csv\"):\n",
    "    df = safe_read_csv(f)\n",
    "    if df is not None:\n",
    "        stocks_dfs.append(df)\n",
    "        \n",
    "for f in TRENDS_DATA.glob(\"*.csv\"):\n",
    "    df = safe_read_csv(f)\n",
    "    if df is not None:\n",
    "        df.set_index('date', inplace=True)\n",
    "        trends_dfs.append(df.iloc[:, 0])\n",
    "\n",
    "\n",
    "assert all(df is not None for df in stocks_dfs), \"Some stock DataFrames failed to load\"\n",
    "assert all(df is not None for df in trends_dfs), \"Some trends DataFrames failed to load\"\n",
    "\n",
    "num_stocks_files = len(list(STOCKS_DATA.glob(\"*.csv\")))\n",
    "num_trends_files = len(list(TRENDS_DATA.glob(\"*.csv\")))\n",
    "\n",
    "print(f\"Loaded {len(stocks_dfs)}/{num_stocks_files} stock data files.\")\n",
    "print(f\"Loaded {len(trends_dfs)}/{num_trends_files} trends data files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b0f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stock_field(df:pd.DataFrame, field:str)->Optional[pd.Series]:\n",
    "    # Check if the field exists in the DataFrame\n",
    "    if field in df.columns:\n",
    "        df_ = df.set_index('Price')\n",
    "        df_ = df_[field].iloc[2:]\n",
    "        df_.index.name='date'\n",
    "        df_.name = df.iloc[0][field]\n",
    "        return df_\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7000c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_shapes = pd.Series({df.iloc[0, 1]: df.shape[0] for df in stocks_dfs}).astype(int)\n",
    "common_length = stocks_shapes.value_counts().index[0]\n",
    "\n",
    "reg_stocks_dfs = [df for df in stocks_dfs if df.shape[0] == common_length]\n",
    "# remove duplicates from list\n",
    "reg_stocks_dfs = list({df.iloc[0, 1]: df for df in reg_stocks_dfs}.values())\n",
    "\n",
    "volume_dfs: List[pd.Series] = []\n",
    "price_dfs: List[pd.Series] = []\n",
    "\n",
    "for df in reg_stocks_dfs:\n",
    "    \n",
    "    volume_sr = parse_stock_field(df, 'Volume')\n",
    "    if volume_sr is not None:\n",
    "        volume_dfs.append(volume_sr)\n",
    "        \n",
    "    price_sr = parse_stock_field(df, 'Close')\n",
    "    if price_sr is not None:\n",
    "        price_dfs.append(price_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec1abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261,)    2409\n",
      "Name: count, dtype: int64\n",
      "(1256,)    75\n",
      "Name: count, dtype: int64\n",
      "(1256,)    75\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "trends_dfs_shapes = pd.Series({df.name: df.shape for df in trends_dfs})\n",
    "print(trends_dfs_shapes.value_counts())\n",
    "\n",
    "price_dfs_shapes = pd.Series({s.name: s.shape for s in price_dfs})\n",
    "print(price_dfs_shapes.value_counts())\n",
    "\n",
    "volume_dfs_shapes = pd.Series({s.name: s.shape for s in volume_dfs})\n",
    "print(volume_dfs_shapes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f979b8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      617\n",
       "261    608\n",
       "2      293\n",
       "3      149\n",
       "4       55\n",
       "5       38\n",
       "6       28\n",
       "8       25\n",
       "11      19\n",
       "10      19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends_variaty = pd.Series({s.name: len(np.nonzero(s)[0]) for s in trends_dfs})\n",
    "trends_variaty.value_counts().head(10)\n",
    "# trends_variaty.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30ce25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1792/2409 interesting trends out of all trends.\n"
     ]
    }
   ],
   "source": [
    "interesting_trends_list: List[pd.Series] = []\n",
    "for trend in trends_dfs:\n",
    "    if len(np.nonzero(trend)[0])>1:\n",
    "        interesting_trends_list.append(trend)\n",
    "\n",
    "print(f'Found {len(interesting_trends_list)}/{len(trends_dfs)} interesting trends out of all trends.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe84f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes_raw = pd.concat(volume_dfs, axis=1).astype(float)\n",
    "prices_raw = pd.concat(price_dfs, axis=1).astype(float)\n",
    "trends_raw = pd.concat(interesting_trends_list, axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d6fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_values_by_date(df:pd.DataFrame)->pd.DataFrame:\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    df_daily = df.resample('D').asfreq()\n",
    "    df_daily = df_daily.interpolate(method='linear')\n",
    "    return df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910b468b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1796, 1792), (1796, 75), (1796, 75))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends = interpolate_values_by_date(trends_raw)\n",
    "prices = interpolate_values_by_date(prices_raw)\n",
    "volumes = interpolate_values_by_date(volumes_raw)\n",
    "\n",
    "index_intersection = trends.index.intersection(prices.index).intersection(volumes.index)\n",
    "index_intersection.shape\n",
    "\n",
    "trends=trends.loc[index_intersection]\n",
    "prices=prices.loc[index_intersection]\n",
    "volumes=volumes.loc[index_intersection]\n",
    "\n",
    "assert trends.index.equals(prices.index) and prices.index.equals(volumes.index), \"Indexes do not match after alignment\"\n",
    "trends.shape, prices.shape, volumes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "369849a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trends.to_csv(PROCESSED_DATA / \"trends.csv\")\n",
    "prices.to_csv(PROCESSED_DATA / \"prices.csv\")\n",
    "volumes.to_csv(PROCESSED_DATA / \"volumes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "needle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
